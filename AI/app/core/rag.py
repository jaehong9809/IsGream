import warnings
import time
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from dotenv import load_dotenv

load_dotenv(override=True)

# OpenAI ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-3.5-turbo")

# OpenAI ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ìµœì í™”
embedding_function = OpenAIEmbeddings()
vectorstore = Chroma(persist_directory="./chroma_db", embedding_function=embedding_function)

# Retriever ì„¤ì • ìµœì í™”
retriever = vectorstore.as_retriever(search_kwargs={"k": 10}, search_type="mmr")  # ê²€ìƒ‰ ê°œìˆ˜ ì¤„ì´ê³  MMR ì ìš©

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì•„ë™ ì‹¬ë¦¬ ìƒë‹´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.  
í•­ìƒ ì˜¨í™”í•˜ê³  ê³µê°ì ì¸ íƒœë„ë¡œ ë³´í˜¸ìì™€ ì•„ì´ì˜ ì´ì•¼ê¸°ë¥¼ ê²½ì²­í•˜ë©°,  
ì•„ë™ì˜ ê°ì •ê³¼ í–‰ë™ì„ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë•ìŠµë‹ˆë‹¤.  

### ì°¸ê³  ë¬¸ì„œ  
{context}  

### ì§ˆë¬¸  
ì•„ë˜ ê²€ì‚¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§‘, ë‚˜ë¬´, ì‚¬ëŒ ê·¸ë¦¼ì˜ ì‹¬ë¦¬ì  ì˜ë¯¸ë¥¼ í•´ì„í•´ ì£¼ì„¸ìš”.  
íŠ¹íˆ, **ê²€ì¶œëœ ëª¨ë“  ê°ì²´ë¥¼ í¬í•¨í•˜ì—¬ ì¤‘ìš”í•œ ì˜ë¯¸ê°€ ë¹ ì§€ì§€ ì•Šë„ë¡ ì„¤ëª…**í•´ ì£¼ì„¸ìš” (í•„ìˆ˜ ê²€ì‚¬ ì‹œê°„ í¬í•¨).  

### ê²€ì‚¬ ê²°ê³¼  
{question}  

### ë¶„ì„ ìš”ì²­  
âœ… **ëª¨ë“  ê°ì²´ë¥¼ ë°˜ì˜í•˜ì—¬ ë¶„ì„í•˜ë˜, ì•„ì´ì˜ ê¸ì •ì ì¸ ë©´ì„ ë¨¼ì € ê°•ì¡°í•˜ê³  í•´ì„í•´ ì£¼ì„¸ìš”.**  
âœ… **ê° ìš”ì†Œì˜ ìœ„ì¹˜ì™€ ì‹¬ë¦¬ì  ì˜ë¯¸ë¥¼ ì—°ê²°í•˜ì—¬ ì„¤ëª…í•´ ì£¼ì„¸ìš”.**  
âœ… **ëˆ„ë½ëœ ìš”ì†Œê°€ ì¤‘ìš”í•œ ì˜ë¯¸ë¥¼ ê°€ì§ˆ ê²½ìš° í•´ì„í•˜ê³ , íŠ¹ë³„í•œ ì˜ë¯¸ê°€ ì—†ìœ¼ë©´ ìƒëµí•´ ì£¼ì„¸ìš”.**  
âœ… **ë¬¸ì œê°€ ìˆë”ë¼ë„ ë¶€ëª¨ê°€ ìƒì²˜ë°›ì§€ ì•Šë„ë¡ ì¡°ì‹¬ìŠ¤ëŸ½ê²Œ ì „ë‹¬í•˜ê³ , ì•„ì´ì˜ ì„±ì¥ ê°€ëŠ¥ì„±ì„ ê°•ì¡°í•´ ì£¼ì„¸ìš”.**  
âœ… **ì‹¬ë¦¬ ìƒë‹´ì‚¬ì˜ ì˜¨í™”í•œ ë§íˆ¬ë¡œ ëŒ€ë‹µí•´ ì£¼ì„¸ìš”.**  
âœ… **ë‹µë³€ì€ 100ìì—ì„œ 200ì ì‚¬ì´ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.**  
""")


# RetrievalQA ì²´ì¸ ìµœì í™”
chain = (
        {"context": retriever, "question": lambda x: x}  # RunnablePassthrough ì œê±°
        | prompt
        | llm
        | StrOutputParser()
)


# ğŸ” **HTP ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ ì‹¤í–‰**
def process_predictions(query):
    print("ğŸ“ HTP ê²€ì‚¬ ë¶„ì„ ì‹œì‘...")

    try:
        start_time = time.time()  # íƒ€ì´ë¨¸ ì‹œì‘
        print("ğŸ¤– LLM ì‘ë‹µ ìƒì„± ì¤‘...")

        response = chain.invoke(query)  # LLM í˜¸ì¶œ

        print(f"âœ… LLM ì‘ë‹µ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ)")
        return response

    except Exception as e:
        print(f"âŒ LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return f"LLM ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
