import warnings
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain_core.prompts import PromptTemplate

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings("ignore", category=DeprecationWarning)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI ëª¨ë¸ ì„¤ì •
llm = ChatOpenAI(model="gpt-4-turbo")

# OpenAI ì„ë² ë”© ëª¨ë¸ ì„¤ì •
embedding_function = OpenAIEmbeddings(model="text-embedding-ada-002")

# ChromaDB ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ
vectorstore = Chroma(persist_directory="app/core/chroma_db", embedding_function=embedding_function)

# Retriever ìƒì„±
retriever = vectorstore.as_retriever(search_kwargs={"k": 10})

print("ğŸ“ ì €ì¥ëœ ë¬¸ì„œ ê°œìˆ˜:", vectorstore._collection.count())

# í”„ë¡¬í”„íŠ¸ ì„¤ì • (RetrievalQAëŠ” {context} ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨)
prompt = PromptTemplate(
    template="""
    ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ HTP(ì§‘-ë‚˜ë¬´-ì‚¬ëŒ) ê²€ì‚¬ í•´ì„ì„ ìˆ˜í–‰í•˜ëŠ” ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
    ì£¼ì–´ì§„ ê²€ì‚¬ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° ìš”ì†Œì˜ ì‹¬ë¦¬ì  ì˜ë¯¸ë¥¼ ë¶„ì„í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.

    ### **HTP ê²€ì‚¬ ê²°ê³¼**
    {context}

    ### **í•´ì„ ì§€ì¹¨**
    1. **ì§‘ ê²€ì‚¬ í•´ì„**  
       - ë¬¸ê³¼ ì°½ë¬¸ì˜ ìœ„ì¹˜ ë° í¬ê¸°  
       - ì§€ë¶•, ë²½ì˜ êµ¬ì¡°ì™€ í˜•íƒœ  
    2. **ë‚˜ë¬´ ê²€ì‚¬ í•´ì„**  
       - ë¿Œë¦¬, ê°€ì§€, ê¸°ë‘¥ì˜ ì˜ë¯¸  
    3. **ì‚¬ëŒ ê²€ì‚¬ í•´ì„**  
       - ì–¼êµ´, ì†, ë°œì˜ í¬ê¸°ì™€ ìœ„ì¹˜  

    ### **ì¶œë ¥ ì˜ˆì‹œ**
    ğŸ”¹ **ì§‘ ê²€ì‚¬ í•´ì„**  
    - ë¬¸ì´ ì‘ê³  ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜ â†’ ë‚´í–¥ì ì¸ ì„±í–¥  
    - ì°½ë¬¸ì´ ì‘ìŒ â†’ ì™¸ë¶€ì™€ì˜ ì†Œí†µ ì œí•œ ê°€ëŠ¥ì„±  

    ğŸ”¹ **ë‚˜ë¬´ ê²€ì‚¬ í•´ì„**  
    - ë¿Œë¦¬ê°€ ì—†ìŒ â†’ ì •ì²´ì„± ë¶€ì¡± ê°€ëŠ¥ì„±  

    ğŸ”¹ **ì‚¬ëŒ ê²€ì‚¬ í•´ì„**  
    - ì–¼êµ´ì´ ì‘ìŒ â†’ ì‚¬íšŒì  ìœ„ì¶• ê°€ëŠ¥ì„±  
    """,
    input_variables=["context"],  # âœ… ë°˜ë“œì‹œ `context` ë³€ìˆ˜ ì‚¬ìš©
)

# RetrievalQA ì²´ì¸ ìƒì„±
qa_chain = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=retriever,
    chain_type="stuff",  # ë¬¸ì„œ ê²°í•© ë°©ì‹ (stuff, map_reduce ë“± ê°€ëŠ¥)
    return_source_documents=True
)


# ğŸ” **HTP ê²€ì‚¬ ê²°ê³¼ ë¶„ì„ ì‹¤í–‰**
def process_predictions(query):
    # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
    docs = retriever.get_relevant_documents(query)

    if not docs:
        print("âŒ ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ë²¡í„° DBë¥¼ ë‹¤ì‹œ ì €ì¥í•˜ì„¸ìš”.")
        return "ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."

    # ëª¨ë¸ ì‘ë‹µ ë°˜í™˜
    response = qa_chain.invoke(query)

    return response["result"]  # `result` í•„ë“œì—ì„œ ì‘ë‹µ ê°€ì ¸ì˜¤ê¸°


